# -*- coding: utf-8 -*-
"""Segmentation CNN rétines.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14GebnC-lLQ4byNWYw4F9BTYahIVOqc8A
"""

import os
import cv2
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
from google.colab import drive
from tensorflow.keras import layers, models
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix
from sklearn.model_selection import train_test_split

drive.mount('/content/gdrive')

# Créer le dossier pour les images prétraitées s'il n'existe pas déjà
output_folder = "/content/gdrive/MyDrive/DRIVE/training/preprocessed_training"
output_folder2 = "/content/gdrive/MyDrive/DRIVE/test/preprocessed_test"
if not os.path.exists(output_folder):
    os.makedirs(output_folder)
if not os.path.exists(output_folder2):
    os.makedirs(output_folder2)

# Chemin vers le dossier contenant les images d'entraînement
input_folder = "/content/gdrive/MyDrive/DRIVE/training/images"

def preprocessed(input_folder, mask_folder, output_folder):
    # Liste de fichiers dans le dossier
    image_files = os.listdir(input_folder)
    # Créer un objet CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    # Parcourir toutes les images dans le dossier
    for image_file in image_files:
        # Charger l'image au format .tif
        image_path = os.path.join(input_folder, image_file)
        tif_image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Chargement en mode non modifié
        image_number = os.path.splitext(image_file)[0].split("_")[0]
        directory = os.path.splitext(image_file)[0].split("_")[1]
        mask_file = f"{image_number}_{directory}_mask.gif"
        mask_path = os.path.join(mask_folder, mask_file)
        mask_image = Image.open(mask_path)
        mask_image = np.array(mask_image)

        # Extraction du canal vert de l'image
        green_channel = tif_image[:, :, 1]

        # Normalisation
        img_mean = np.mean(green_channel)
        img_stddev = np.std(green_channel)
        img_normalized = (green_channel - img_mean) / img_stddev

        # Convertir img_normalized en format 8 bits (CV_8UC1)
        img_normalized = cv2.normalize(img_normalized, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

        # Appliquer CLAHE pour égaliser l'histogramme
        equalized_image = clahe.apply(img_normalized)

        # Appliquer un ajustement gamma
        gamma = 1.5
        gamma_corrected = np.power(equalized_image, gamma)

        # Normalisation des valeurs entre 0 et 1
        normalized_image = cv2.normalize(gamma_corrected, None, 0, 1, cv2.NORM_MINMAX)
        normalized_image = np.where(mask_image != 0, normalized_image, 0)
        resized_image = cv2.resize(normalized_image, (560, 560))

        # Enregistrer l'image prétraitée en .jpg dans le dossier de sortie
        output_path = os.path.join(output_folder, os.path.splitext(image_file)[0] + ".jpg")
        cv2.imwrite(output_path, (normalized_image * 255).astype(np.uint8))

    print("Prétraitement terminé. Les images prétraitées ont été enregistrées au format .jpg dans le dossier", output_folder)

mask_folder = "/content/gdrive/MyDrive/DRIVE/training/mask"
preprocessed(input_folder, mask_folder, output_folder)

input_folder = "/content/gdrive/MyDrive/DRIVE/training/preprocessed_training"

# Chemin vers le dossier contenant les images ground truth (segmentées à la main) au format .jpg
gt_folder = "/content/gdrive/MyDrive/DRIVE/training/1st_manual"

# Liste de fichiers dans le dossier
image_files = os.listdir(input_folder)

# Taille des patchs
patch_size = (28, 28)

# Créer des listes pour stocker les données et les étiquettes
X_data = []
y_data = []

# Parcourir toutes les images dans le dossier
for image_file in image_files:
    # Charger l'image prétraitée
    image_path = os.path.join(input_folder, image_file)
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)/255

    # Extraire le numéro d'image du nom du fichier (nombre_training.jpg)
    image_number = os.path.splitext(image_file)[0].split("_")[0]

    # Construire le nom du fichier ground truth correspondant (nombre_manual1.gif)
    gt_file = f"{image_number}_manual1.gif"
    gt_path = os.path.join(gt_folder, gt_file)
    gt_image = Image.open(gt_path)
    gt_image = np.array(gt_image)

    # Découper l'image en patchs de 28x28 pixels
    for i in range(0, image.shape[0] - patch_size[0] + 1, 28):
        for j in range(0, image.shape[1] - patch_size[1] + 1, 28):
            patch = image[i:i+patch_size[0], j:j+patch_size[1]]
            X_data.append(patch)

            # Utiliser l'image ground truth correspondante comme étiquette
            gt_patch = gt_image[i:i+patch_size[0], j:j+patch_size[1]]
            y_data.append(1-gt_patch/255)

# Convertir les listes en tableaux NumPy
X_data = np.array(X_data)
y_data = np.array(y_data)

# Diviser les données en ensembles d'entraînement et de validation (80% - 20%)
X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)

# Charger l'ensemble de test à partir du dossier "test"
test_folder = "/content/gdrive/MyDrive/DRIVE/test/images"

# Liste de fichiers dans le dossier
test_image_files = os.listdir(test_folder)
X_test = []
test_mask_folder = "/content/gdrive/MyDrive/DRIVE/test/mask"
preprocessed(test_folder, test_mask_folder, output_folder2)
test_folder = "/content/gdrive/MyDrive/DRIVE/test/preprocessed_test"
test_image_files = os.listdir(test_folder)

# Taille des patchs
patch_size = (28, 28)

# Parcourir toutes les images dans le dossier
for image_file in test_image_files:
    # Charger l'image prétraitée
    image_path = os.path.join(test_folder, image_file)
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)/255

    # Découper l'image en patchs de 28x28 pixels
    for i in range(0, image.shape[0] - patch_size[0] + 1, 28):
        for j in range(0, image.shape[1] - patch_size[1] + 1, 28):
            patch = image[i:i+patch_size[0], j:j+patch_size[1]]
            X_test.append(patch)

# Convertir les listes en tableaux NumPy
X_test = np.array(X_test)

# Créer une nouvelle architecture de réseau
model = models.Sequential([
    layers.Input(shape=(28, 28, 1)),  # Couche d'entrée pour des images de taille 28x28x1

    # Première couche convolutive (C1)
    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
    layers.Dropout(0.7),  # Couche de dropout

    # Deuxième couche convolutive (C2)
    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
    layers.Dropout(0.7),  # Couche de dropout

    # Couche de max-pooling (M1)
    layers.MaxPooling2D((2, 2), strides=2),

    # Troisième couche convolutive (C3)
    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
    layers.Dropout(0.7),  # Couche de dropout

    # Quatrième couche convolutive (C4)
    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
    layers.Dropout(0.7),  # Couche de dropout

    # Couche d'upsampling (U1)
    layers.Conv2DTranspose(64, (2, 2), strides=2),

    # Cinquième couche convolutive (C5)
    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
    layers.Dropout(0.7),  # Couche de dropout

    # Sixième couche convolutive (C6)
    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
    layers.Dropout(0.7),

    # Couche de sortie
    layers.Conv2D(1, (3, 3), padding='same', activation='softmax')
])

model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, momentum=0.7),
                  loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()
model.fit(X_train, y_train, epochs=60, verbose=1)

# Chemin pour enregistrer le modèle
model_save_path = "/content/gdrive/MyDrive/DRIVE/training/model_saved.h5"

# Sauvegarder le modèle
model.save(model_save_path)
print("Modèle sauvegardé avec succès.")

# Charger le modèle sauvegardé
#model = keras.models.load_model(model_save_path)

# Évaluer le modèle sur l'ensemble de validation
validation_predictions = model.predict(X_val)

# Évaluer le modèle sur l'ensemble de test
test_predictions = model.predict(X_test)

# Seuil de classification
threshold = 0.5

# Convertir les prédictions en étiquettes (0 ou 1) en utilisant le seuil
validation_labels_predicted = (validation_predictions > threshold).astype(int)
y_val = y_val.reshape(-1)
validation_labels_predicted = validation_labels_predicted.reshape(-1)
validation_predictions = validation_predictions.reshape(-1)

# Calcul de la précision
precision = precision_score(y_val, validation_labels_predicted)

# Calcul de la sensibilité (recall)
sensitivity = recall_score(y_val, validation_labels_predicted)

# Calcul de la spécificité
confusion = confusion_matrix(y_val, validation_labels_predicted)
specificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1])

# Calcul de l'accuracy
accuracy = accuracy_score(y_val, validation_labels_predicted)

# Calcul de l'AUC (Area Under the ROC Curve)
roc_auc = roc_auc_score(y_val, validation_predictions)

print(f"Précision : {precision}")
print(f"Sensibilité : {sensitivity}")
print(f"Spécificité : {specificity}")
print(f"Accuracy : {accuracy}")
print(f"AUC : {roc_auc}")

# Dimensions des images originales
original_image_height = 560
original_image_width = 560

# Créer une liste pour stocker les images segmentées prédites
segmented_images = []

# Nombre de patchs en hauteur et en largeur pour chaque image
num_patch_height = (original_image_height - patch_size[0] + 1) // 28
num_patch_width = (original_image_width - patch_size[1] + 1) // 28

# Indice pour suivre les prédictions dans test_predictions
index = 0

# Parcourir chaque image dans X_test
for i in range(len(test_image_files)):
    # Créer une image vide pour reconstituer les prédictions
    segmented_image = np.zeros((original_image_height, original_image_width), dtype=np.float32)

    for h in range(num_patch_height):
        for w in range(num_patch_width):
            # Récupérer la prédiction de ce patch
            patch_prediction = test_predictions[index]

            # Position d'origine du patch dans l'image complète
            patch_top = h * 28
            patch_left = w * 28

            # Appliquer la prédiction du patch à la position d'origine
            segmented_image[patch_top:patch_top+28, patch_left:patch_left+28] += patch_prediction[0]

            # Incrémenter l'index pour passer à la prochaine prédiction
            index += 1

    # Ajouter l'image segmentée à la liste
    segmented_images.append(segmented_image)

# Créer un dossier "segmented" s'il n'existe pas
output_folder_segmented = "/content/gdrive/MyDrive/DRIVE/test/segmented"
if not os.path.exists(output_folder_segmented):
    os.makedirs(output_folder_segmented)

# Parcourir les images segmentées et les enregistrer dans le dossier "segmented"
for i, segmented_image in enumerate(segmented_images):
    # Créer un nom de fichier pour l'image segmentée
    image_filename = f"segmented_image_{i + 1}.png"

    # Chemin complet pour enregistrer l'image segmentée
    image_path = os.path.join(output_folder_segmented, image_filename)

    # Créer une image PIL à partir de l'array NumPy
    segmented_image_pil = Image.fromarray((segmented_image * 255).astype('uint8'))

    # Enregistrer l'image au format PNG
    segmented_image_pil.save(image_path)

print("Les images segmentées ont été enregistrées dans le dossier 'test/segmented'.")